{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Input File Requirement to Generate Publications:\n",
    "1. People ID (Row number recommended)\n",
    "2. First Name\n",
    "3. Last Name\n",
    "4. Searched Term\n",
    "5. Extra Information(Any Columns)\n",
    "\n",
    "## Remember:\n",
    "#####  The only needed variables are the first 4. The rest variables will be kept as the input for later comparation.\n",
    "\n",
    "## ReadMe!!!!, Update Description:\n",
    "1. Now the input name and searched term are auto-collected to the ouput\n",
    "2. Now it is a Full name Matching Algorithm!!!!!!!!\n",
    "3. Latin Name, Letter Case Don't affect the Name Matching\n",
    "4. A lot of useless columns droped.\n",
    "5. Any amounts of Extra Information are available now!!!!!!!!!!!!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries \n",
    "# Entrez is one library adapting the E-Utilities functions of Pubmed search for Python\n",
    "# Note: no more than 3 queries/second using E-Utilities or more than 100,000 results / query -- will require setting up API Key from Pubmed\n",
    "from Bio import Entrez\n",
    "import pprint \n",
    "import numpy as np\n",
    "import pandas as pd                 \n",
    "from datetime import datetime\n",
    "import os\n",
    "import re     \n",
    "import unidecode as un\n",
    "#Register the API in PubMed!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "Entrez.email = \"juan.lin@h1insights.com\"\n",
    "Entrez.api_key = \"9178358b4680ef4964a19857085715b84507\"\n",
    "\n",
    "\n",
    "# Set your directory\n",
    "os.chdir('C:/Users/Juan/Desktop/ipython')\n",
    "df = pd.read_excel(\"HKfull.xlsx\", index_col = None)  \n",
    "\n",
    "file_name = \"HKfull\"\n",
    "\n",
    "searchterm = \"search='({} {}[Author]) AND ({}[Affiliation])'.format(authorfirst, authorlast, org)\"\n",
    "#searchterm = \"search='{} {} {}'.format(authorfirst, authorlast, org)\"\n",
    "#searchterm = \"search='{} {}[Author]'.format(authorfirst, authorlast)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate dataframe representing Pubmed search for one person with article information: Name, Organization Affiliation, Title of Paper, DOI \n",
    "def generator(PMID, record,shape):\n",
    "    # initiate dictionaries for storing the different columns of information, will at end convert dictionary to series to pandas dataframe\n",
    "    # dictionary adds additional security because keeps PMID value for the article information we're seeking\n",
    "    dicts = {}\n",
    "    dicts2 = {}\n",
    "    dicts3 = {}\n",
    "    dicts4 = {}\n",
    "    title = []                           #article title - /ArticleTitle \n",
    "    CT = []                              #clinical trial - /DataBankList\n",
    "    date = []                           #publication date - /Journal/PubDate\n",
    "    peopleID = []                        #\n",
    "    journal = []                        #journal title - /Journal/Title\n",
    "    matchto = []\n",
    "    #Conditional - Do not active!\n",
    "    #org =[]  #Taiwan\n",
    "    #inputname = []\n",
    "    #department =[]\n",
    "    #inputaffiliation = [] #China\n",
    "\n",
    "\n",
    "\n",
    "    # iterates through the individual articles\n",
    "    # length of pubmed articles in records (not PMID, because this will not include book articles (included in records at very end))\n",
    "    for i in range(len(record['PubmedArticle'])):\n",
    "        # initialize list for individual article doi, affiliation, name \n",
    "        peopleID.append(ID)\n",
    "        matchto.append(info)\n",
    "        #Conditional\n",
    "       # inputname.append(inputname)\n",
    "        #org.append(org)\n",
    "        #department.append(department)\n",
    "        #matchto.append(info)\n",
    "       # inputaffiliation.append(inputaffiliation) #China\n",
    "        \n",
    "        \n",
    "        doi = []                        #doi - /ELocationID & EIdType == \"doi\"\n",
    "        affiliation = []\n",
    "        mesh = []                       #Mesh -/MeshHeadingList\n",
    "        name = []                       #Author Name - /AuthorList/ForeName + '' + /AuthorList/LastName\n",
    "        # Titles of articles in list\n",
    "        title.append(record['PubmedArticle'][i]['MedlineCitation']['Article']['ArticleTitle'])\n",
    "        # Journal of which articles were published in \n",
    "        journal.append(record['PubmedArticle'][i]['MedlineCitation']['Article']['Journal']['Title'])\n",
    "        # Existence of clinical trial link in the Article                                                                                    \n",
    "        if 'DataBankList' in record['PubmedArticle'][i]['MedlineCitation']['Article']:\n",
    "            CT.append(record['PubmedArticle'][i]['MedlineCitation']['Article']['DataBankList'][0]['AccessionNumberList'][0])\n",
    "        else: \n",
    "            CT.append(\"NA\")\n",
    "        # Publication date of paper\n",
    "        if 'PubDate' in record['PubmedArticle'][i]['MedlineCitation']['Article']['Journal']['JournalIssue']:\n",
    "            if 'Year' in record['PubmedArticle'][i]['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']:\n",
    "                if 'Month' in record['PubmedArticle'][i]['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']:\n",
    "                    year = record['PubmedArticle'][i]['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']['Year']\n",
    "                    month = record['PubmedArticle'][i]['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']['Month']\n",
    "                    fulldate = month + ' ' + year\n",
    "                    date.append(fulldate)\n",
    "                else: \n",
    "                    date.append(record['PubmedArticle'][i]['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']['Year'])     \n",
    "            else: \n",
    "                date.append(\"NA\")                                                                                                           \n",
    "        for j in range(len(record['PubmedArticle'][i]['MedlineCitation']['Article']['ELocationID'])):\n",
    "            strings = record['PubmedArticle'][i]['MedlineCitation']['Article']['ELocationID'][j]\n",
    "            # searches and selects for ID type that is DOI (PII also found here)\n",
    "            if strings.attributes['EIdType'] == \"doi\": \n",
    "                doi.append(strings)\n",
    "        # one PMID, one DOI \n",
    "        dicts[PMID[i]] = doi\n",
    "        # iterates through author list to search for correct person and affiliation\n",
    "        for k in range(len(record['PubmedArticle'][i]['MedlineCitation']['Article']['AuthorList'])):                                    \n",
    "            authors = record['PubmedArticle'][i]['MedlineCitation']['Article']['AuthorList'][k]\n",
    "            # if author has an author affiliation\n",
    "            if 'LastName' and 'ForeName' in authors:\n",
    "                fullname_Pub=un.unidecode(authors['ForeName'].upper())+' '+un.unidecode(authors['LastName'].upper())\n",
    "                fullname_Input=un.unidecode(authorfirst.upper())+' '+un.unidecode(authorlast.upper())                \n",
    "                if authors['AffiliationInfo'] != [] and fullname_Pub.replace('-',' ')==fullname_Input.replace('-',' '):    \n",
    "                    # match on fullname \n",
    "                        #if un.unidecode(authors['LastName']).upper() == un.unidecode(authorlast.upper()) and un.unidecode(authors['ForeName'].upper()) == un.unidecode(authorfirst.upper()):  \n",
    "                    firstname = authors['ForeName']\n",
    "                    lastname = authors['LastName']\n",
    "                    fullname = firstname + ' ' + lastname\n",
    "                    name.append(fullname)\n",
    "                        # collect all affiliations attributed to the matched author\n",
    "                    for l in range(len(authors['AffiliationInfo'])):\n",
    "                        affiliation.append(authors['AffiliationInfo'][l]['Affiliation'])\n",
    "                # in the cases for which author affiliation is blank, assign to the affiliation of the first   \n",
    "                #elif 'LastName' and 'ForeName' in authors and un.unidecode(authors['LastName'].upper()) == un.unidecode(authorlast.upper()) and un.unidecode(authors['ForeName'].upper()) == un.unidecode(authorfirst.upper()):\n",
    "                elif fullname_Pub.replace('-',' ')==fullname_Input.replace('-',' '): \n",
    "                    firstname = authors['ForeName']\n",
    "                    lastname = authors['LastName']\n",
    "                    fullname = firstname + ' ' + lastname\n",
    "                    name.append(fullname)\n",
    "                    if record['PubmedArticle'][i]['MedlineCitation']['Article']['AuthorList'][0]['AffiliationInfo'] != []:\n",
    "                        for l in range(len(record['PubmedArticle'][i]['MedlineCitation']['Article']['AuthorList'][0]['AffiliationInfo'])):\n",
    "                            conditionalaff = \"FIRST AUTHOR AFFILIATION: \" + record['PubmedArticle'][i]['MedlineCitation']['Article']['AuthorList'][0]['AffiliationInfo'][l]['Affiliation']\n",
    "                            affiliation.append(conditionalaff)\n",
    "            elif 'ForeName' in authors:\n",
    "                fullname_Pub=un.unidecode(authors['ForeName'].upper())\n",
    "                fullname_Input=un.unidecode(authorfirst.upper())+' '+un.unidecode(authorlast.upper())                \n",
    "                if authors['AffiliationInfo'] != [] and fullname_Pub.replace('-',' ')==fullname_Input.replace('-',' '):    \n",
    "                    fullname = authors['ForeName']\n",
    "                    name.append(fullname)\n",
    "                        # collect all affiliations attributed to the matched author\n",
    "                    for l in range(len(authors['AffiliationInfo'])):\n",
    "                        affiliation.append(authors['AffiliationInfo'][l]['Affiliation'])\n",
    "                elif fullname_Pub.replace('-',' ')==fullname_Input.replace('-',' '): \n",
    "                    fullname = authors['ForeName']\n",
    "                    name.append(fullname)\n",
    "                    if record['PubmedArticle'][i]['MedlineCitation']['Article']['AuthorList'][0]['AffiliationInfo'] != []:\n",
    "                        for l in range(len(record['PubmedArticle'][i]['MedlineCitation']['Article']['AuthorList'][0]['AffiliationInfo'])):\n",
    "                            conditionalaff = \"FIRST AUTHOR AFFILIATION: \" + record['PubmedArticle'][i]['MedlineCitation']['Article']['AuthorList'][0]['AffiliationInfo'][l]['Affiliation']\n",
    "                            affiliation.append(conditionalaff)\n",
    "             #   elif record['PubmedArticle'][i]['MedlineCitation']['Article']['AuthorList'][-1]['AffiliationInfo'] != []:\n",
    "            #        firstname = authors['ForeName']\n",
    "             #       lastname = authors['LastName']\n",
    "             #       fullname = firstname + ' ' + lastname\n",
    "             #       name.append(fullname)\n",
    "             #       for l in range(len(record['PubmedArticle'][i]['MedlineCitation']['Article']['AuthorList'][-1]['AffiliationInfo'])): #NEW\n",
    "              #          conditionalaff = \"LAST AUTHOR AFFILIATION: \" + record['PubmedArticle'][i]['MedlineCitation']['Article']['AuthorList'][0]['AffiliationInfo'][l]['Affiliation'] #NEW\n",
    "              #          affiliation.append(conditionalaff) #NEW\n",
    "              #          \n",
    "\n",
    "        # iterate through mesh headings \n",
    "        if 'MeshHeadingList' in record['PubmedArticle'][i]['MedlineCitation']:\n",
    "            for m in range(len(record['PubmedArticle'][i]['MedlineCitation']['MeshHeadingList'])): \n",
    "                # [:] allows for getting all of the inside (no string element values) when exporting the dataframe into excel \n",
    "                keywords = record['PubmedArticle'][i]['MedlineCitation']['MeshHeadingList'][m]['DescriptorName'][:]\n",
    "                mesh.append(keywords)\n",
    "            \n",
    "        dicts2[PMID[i]] = affiliation\n",
    "        dicts3[PMID[i]] = name\n",
    "        dicts4[PMID[i]] = mesh\n",
    "        \n",
    "    # dictionary to series to dataframe, named columns\n",
    "    dicts = pd.Series(dicts).to_frame()                                                                                                                               \n",
    "    dicts.columns = ['DOI']\n",
    "    dicts2 = pd.Series(dicts2).to_frame()\n",
    "    dicts2.columns = ['Affiliation']\n",
    "    dicts2.Affiliation.apply(tuple)                                                                                                                                    \n",
    "    dicts3 = pd.Series(dicts3).to_frame()\n",
    "    dicts3.columns = ['Name']\n",
    "    dicts4 = pd.Series(dicts4).to_frame()\n",
    "    dicts4.columns = ['Mesh']    \n",
    "    \n",
    "    #join into one dataframe, nice formatting\n",
    "    publications = dicts2.join(dicts3)\n",
    "    #publications = dicts2.join(dicts3)\n",
    "    #publications.DOI = publications.DOI.str[0]\n",
    "    #publications.Name = publications.Name.str[0]\n",
    "    publications['Title'] = title\n",
    "    #publications['Clinical Trials'] = CT\n",
    "    #publications['Date'] = date\n",
    "    publications['PeopleID'] = peopleID\n",
    "    #publications['Journal'] = journal\n",
    "    publications['Searched Term'] = matchto\n",
    "    #Conditional\n",
    "    #publications['Department'] = department \n",
    "    #publications['Input Affiliation'] = org   #Taiwan\n",
    "    #publications['Input Affiliation'] = inputaffiliation  #China\n",
    "    publications['Input Name'] = inputname\n",
    "    #China\n",
    "    #publications['Input Affiliation'] = inputname\n",
    "    \n",
    "    #publications = publications.join(dicts4)\n",
    "    if shape>4:\n",
    "        for i in range(5,shape+1):\n",
    "            exec('publications[{0}Extra_{1}{0}] = extra_{2}'.format(\"'\",i-4,i-4))    \n",
    "\n",
    "    return publications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# CASE 1: Search with search terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>AffiliationInstitution</th>\n",
       "      <th>specialty</th>\n",
       "      <th>specialty.1</th>\n",
       "      <th>FullName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1744</td>\n",
       "      <td>Chu Peng</td>\n",
       "      <td>Hoi</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>山頂醫院_Neurology</td>\n",
       "      <td>Neurology</td>\n",
       "      <td>Neurology|NEURO_Neurologist Rx MS |Neurology</td>\n",
       "      <td>Chu Peng (Inactive) Hoi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Row  FirstName LastName Unnamed: 3 AffiliationInstitution  specialty  \\\n",
       "0  1744  Chu Peng       Hoi  Hong Kong         山頂醫院_Neurology  Neurology   \n",
       "\n",
       "                                    specialty.1                 FullName  \n",
       "0  Neurology|NEURO_Neurologist Rx MS |Neurology  Chu Peng (Inactive) Hoi  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.set_option('max_colwidth', 300)\n",
    "pd.set_option('display.max_rows', 6)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8861904144287109"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publications=pd.core.frame.DataFrame()\n",
    "import time\n",
    "start=time.time()\n",
    "placeholder = []\n",
    "noresults1 = []\n",
    "noresults2 = []\n",
    "noresults3 = []\n",
    "shape=df.shape[1]\n",
    "for row in df.itertuples(): \n",
    "    ID = row[1]\n",
    "    authorfirst = row[2].strip()\n",
    "    authorlast = row[3].strip()\n",
    "    org = row[4]   #Taiwan\n",
    "\n",
    "    info = row[4]\n",
    "        \n",
    "    inputname = str(row[2])+' '+str(row[3])\n",
    "    #extra\n",
    "    if shape>4:\n",
    "        for i in range(5,shape+1):\n",
    "            exec('extra_{}=row[{}]'.format(i-4,i))\n",
    "    \n",
    "    exec(searchterm)  \n",
    "    \n",
    "    \n",
    "    # E-utiltiies esearch searches pubmed, returns max of 500 articles\n",
    "    handle = Entrez.esearch(db = \"pubmed\", term = search, retmax = 5)  #set retmax = 5 for Taiwan\n",
    "    # read parses and returns in simplified format\n",
    "    record = Entrez.read(handle)\n",
    "    # in the case that search results exist\n",
    "               # in the case that search results exist\n",
    "    if 'ErrorList' in record: \n",
    "        noresults1.append(ID)\n",
    "        noresults2.append(info)\n",
    "        noresults3.append(\"No Relevant Results\")\n",
    "        \n",
    "    elif record['IdList'] != []:\n",
    "        # this is list of PMIDs from search\n",
    "        PMID = record['IdList']  \n",
    "        # input PMID list of articles into efetch, returns XML of articles\n",
    "        handle = Entrez.efetch(db=\"pubmed\", id=PMID, retmode=\"xml\")\n",
    "        # parses accordingly\n",
    "        record2 = Entrez.read(handle)\n",
    "        # run function to get list of dataframes (one dataframe for each person), concat dataframe together\n",
    "        publication = generator(PMID, record2,shape)\n",
    "        placeholder.append(publication)\n",
    "    else: \n",
    "        noresults1.append(ID)\n",
    "        noresults2.append(info)\n",
    "        noresults3.append(\"No Results\")\n",
    "if placeholder==[]:\n",
    "    print(\"No Results!!! Try Another Searched Term\")\n",
    "else:\n",
    "    publications = pd.concat(placeholder)\n",
    "end=time.time()\n",
    "run_time=end-start\n",
    "run_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Affiliation</th>\n",
       "      <th>Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>PeopleID</th>\n",
       "      <th>Searched Term</th>\n",
       "      <th>Input Name</th>\n",
       "      <th>Extra_1</th>\n",
       "      <th>Extra_2</th>\n",
       "      <th>Extra_3</th>\n",
       "      <th>Extra_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29217662</th>\n",
       "      <td>[Department of Neurology, Institute of Interna...</td>\n",
       "      <td>[Chu Peng Hoi]</td>\n",
       "      <td>Long-Term Prognostic Implications of Cerebral ...</td>\n",
       "      <td>1744</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>Chu Peng  Hoi</td>\n",
       "      <td>山頂醫院_Neurology</td>\n",
       "      <td>Neurology</td>\n",
       "      <td>Neurology|NEURO_Neurologist Rx MS |Neurology</td>\n",
       "      <td>Chu Peng (Inactive) Hoi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20878707</th>\n",
       "      <td>[School of Pharmacy, The Chinese University of...</td>\n",
       "      <td>[Chu Peng Hoi]</td>\n",
       "      <td>Neuroprotective effect of honokiol and magnolo...</td>\n",
       "      <td>1744</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>Chu Peng  Hoi</td>\n",
       "      <td>山頂醫院_Neurology</td>\n",
       "      <td>Neurology</td>\n",
       "      <td>Neurology|NEURO_Neurologist Rx MS |Neurology</td>\n",
       "      <td>Chu Peng (Inactive) Hoi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Affiliation            Name  \\\n",
       "29217662  [Department of Neurology, Institute of Interna...  [Chu Peng Hoi]   \n",
       "20878707  [School of Pharmacy, The Chinese University of...  [Chu Peng Hoi]   \n",
       "\n",
       "                                                      Title  PeopleID  \\\n",
       "29217662  Long-Term Prognostic Implications of Cerebral ...      1744   \n",
       "20878707  Neuroprotective effect of honokiol and magnolo...      1744   \n",
       "\n",
       "         Searched Term     Input Name         Extra_1    Extra_2  \\\n",
       "29217662     Hong Kong  Chu Peng  Hoi  山頂醫院_Neurology  Neurology   \n",
       "20878707     Hong Kong  Chu Peng  Hoi  山頂醫院_Neurology  Neurology   \n",
       "\n",
       "                                               Extra_3  \\\n",
       "29217662  Neurology|NEURO_Neurologist Rx MS |Neurology   \n",
       "20878707  Neurology|NEURO_Neurologist Rx MS |Neurology   \n",
       "\n",
       "                          Extra_4  \n",
       "29217662  Chu Peng (Inactive) Hoi  \n",
       "20878707  Chu Peng (Inactive) Hoi  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [No Results, Search Term, Reason]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "if searchterm == \"search='{} {}[Author]'.format(authorfirst, authorlast)\":\n",
    "    file_name=file_name+'_Name Only'\n",
    "elif searchterm == \"search='({} {}[Author]) AND ({}[Affiliation])'.format(authorfirst, authorlast, org)\":\n",
    "    file_name=file_name+'_Name With Info'\n",
    "\n",
    "noresults = pd.DataFrame(\n",
    "    {'No Results': noresults1,\n",
    "     'Search Term': noresults2,\n",
    "     'Reason': noresults3\n",
    "    })\n",
    "pprint.pprint(noresults) \n",
    "# print(noresults2)\n",
    "\n",
    "noresults.to_excel(f'{file_name}_Noresults.xlsx')\n",
    "\n",
    "#now = datetime.now()\n",
    "#date_time = now.strftime(\"%Y%m%d\")\n",
    "publications.to_excel(f'{file_name}_Output.xlsx')\n",
    "#De empty\n",
    "#Output1=pd.read_excel(f'{file_name}_Output1.xlsx', index_col = None)  \n",
    "#Output1_clear=Output1.drop(Output1[Output1['Name']=='[]'].index)\n",
    "#Output1_clear.to_excel(f'{file_name}_Output2.xlsx')\n",
    "#noresults_2 = pd.DataFrame(\n",
    "#    {'No Results':list(set(list(Output1['PeopleID'][Output1[Output1['Name']=='[]'].index])+noresults1))\n",
    "#    })\n",
    "#pprint.pprint(noresults_2)\n",
    "#noresults_2.to_excel(f'{file_name}Noresults.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
